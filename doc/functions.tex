\documentclass[a4paper]{article}
\usepackage[pagebackref=true]{hyperref}
\usepackage[hyperref]{xcolor}
\usepackage{geometry}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{dot2texi}
\usepackage{algorithm2e}
\usepackage{pdflscape}

\setlength{\parskip}{.5em}
\setlength{\parindent}{0em}

\DeclareMathOperator{\hash}{Hash}
\DeclareMathOperator{\hashvrfy}{Verify_{Hash}}
\DeclareMathOperator{\hmac}{HMAC}
\DeclareMathOperator{\hmacinline}{HMAC_{Inline}}
\DeclareMathOperator{\hmacvrfy}{Verify_{HMAC}}
\DeclareMathOperator{\enc}{Encrypt}
\DeclareMathOperator{\dec}{Decrypt}
\DeclareMathOperator{\sign}{Sign}
\DeclareMathOperator{\signvrfy}{Verify_{Sig}}
\DeclareMathOperator{\id}{Id}
\DeclareMathOperator{\trans}{Transform}
\DeclareMathOperator{\rand}{Rand}
\DeclareMathOperator{\dhsec}{DH_{Sec}}
\DeclareMathOperator{\dhpub}{DH_{Pub}}
\DeclareMathOperator{\guard}{Guard}
\DeclareMathOperator{\release}{Release}
\DeclareMathOperator{\const}{Const}
\DeclareMathOperator{\permute}{Permute}

\newcommand{\TODO}[1]{\small\noindent\color{red} TODO: #1\color{black}}

\newcommand{\emptysec}{\varnothing}
\newcommand{\secminus}{\smallsetminus}

\definecolor{myblue}{HTML}{0091FF}
\hypersetup
{
    colorlinks = true,
    linkcolor  = myblue,
    citecolor  = myblue
}

\begin{document}

\section{\label{sec:cbs}Component-based systems}

- all software has errors, bug-free software is impossible

- the larger the software/system, the more bugs are in there

- many of them are security critical, bad especially for protection systems like chat encryption, VPNs etc


- solution: component-based systems, use of micro kernel/SK, isolation of different components

- Emerging trend: SGX etc. which also motivates isolated implementation of components

- Mechanisms are well understood, but arbitrary segregation of a systems may not even improve security

- EXAMPLE: VPN gateway with VPN Linux - every attack possible through the network still works there, complexity added by micro kernel etc.


- What is relevant for the security then? The trusted computing base!

- TCB: (we use HÃ¤rtigs modern definition, cite) all software that must be trusted to achieve some security objective

- EXAMPLE: There can be many: One for keeping WiFi password secret, one for confidentiality of my network connection another for integrity of my files


- Goal: Minimize the TCB for a particular, implement as much in untrusted legacy components as feasible

- But how is such a system structured to achieve minimal TCB while maintaining security goals?

- EXAMPLE: Untrusted implementation of signature check

- True component-based systems used in various places in industry and academia: uSINA, MLW, TKM, VPFS, Genode

- Despite these examples, we do not seem to understand how the separation is done systematically beyond a gut feeling

- We present another manual segregation of the OTR protocol and an approach to automatically find component-based implementation based the specification of a crypto protocol

\section{\label{sec:manual_modularization}Manual modularization of OTR}

\subsection{Off-the-Record Messaging Protocol}

- security protocol designed to provide security for instant messaging

- Agnostic to the underlying chat protocol, i.e. can be integrated with different messaging clients and protocols

- Security objectives

    - Confidentiality
    - Authentication
    - Deniability: Forge messages after conversation has ended
    - PFS

- Protocol description (AKE part, SMP left out) as described in OTR v3 spec: 

    - based on the SIGMA protocol (citation needed)

    - encrypted channel through unauthenticated DH 

    - perform mutual authentication inside that channel

    - Graphics of protocol messages

    - Connection setup between Alice and Bob consist of 5 messages

        - Query -> Request OTR session over an insecure channel, may also be embedded in regular messages through a whitespace encoding
        - DH-Commit: First message where Alice commits to a DH encryption key gx without revealing it to Bob, yet. Done by sending it encrypted without reveling the respective key x
        - DH-Key: Bob sends its DH encryption key gy
        - Reveal-Signature: Alice reveals its DH encryption key by sending key x and authenticates herself and the channel parameters using a digital signature
        - Signature: Bob authenticates himself and the channel parameters, again using a digital signature

    - After connection setup data messages convey the actual private messages

        - With every message pair between Alice and Bob, a new DH key exchange is performed
        - Old MAC keys are revealed when new keys have been negotiated and no messages secured with the old key are in transition anymore
        - This allows an attacker to forge (but not decrypt) messages *after* the conversation took place
        - This creates the deniability property

    - From the shared secret, a secure session ID is derived

        - allows for mutual authentication of the connection by comparing the value on a different channel
        - works even if the identity of the public keys is unknown
        - Alternative: SMP

- Reference implementation in C and Java exist and are used by most of the existing OTR-capable clients

- To ease integration with existing software, both implementations are monolithic

- Messages are passed to a libotr library function, the finished message are passed to a callback - the client just needs to send it

- Problem: Much functionality is not even security critical (message creation, database lookup) -> unnecessarily large TCB


\subsection{Modularization of OTR}

- 

\section{\label{sec:automatic_modularization}Automatic modularization of cryptographic protocols}

\subsection{Notation}

Security requirements are denoted by $c$ (Confidentiality), $i$ (Integrity) and
$f$ (Freshness). The overall security requirement some domain $D$ must fulfill
is denoted by a set $S_D$ over these properties. For a domain $D_1$ which has
to guarantee integrity, but no other properties, this would be:

$$S_{D_1} = \{i\}$$

A domain $D_2$ which does not (need) to fulfill any security requirements has
the following set:

$$S_{D_2} = \emptysec$$

Operations that make up a cryptographic protocol impose preconditions on the
requirement set of their input parameters. These preconditions need to be
guaranteed by the calling domain. Likewise, the results of an operation may
impose security requirements on the receiving domain.

Note, that this is opposite to e.g. Hoard logic (citation needed) where the
execution of a program is guaranteed to establish some postcondition, given its
precondition is satisfied. In our logic we rather remove the requirements that
an operation guarantees from the resulting security requirements set only
leaving those that still need to be guaranteed by the receiving domain. This
enables us to reason about domain-wide requirements and to split up domains
with equal into isolated partitions to reduce the trusted computing base.

An operation $O$ has input parameters $i_k$ and output parameters $o_j$ which
each have an associated security requirement set $\iota_k$ and $\omega_j$
respectively:

$$P(i_1^{\iota_1}, \cdots, i_n^{\iota_n}) \mapsto (o_1^{\omega_1}, \cdots, o_m^{\omega_m})$$

How the resulting security requirements sets relate to the sets of the input
parameters depends on the semantics of an operation $O$. The most important
primitives used in cryptographic protocols are detailed in the following
section.

\subsection{Primitives}

\subsubsection{Transformations}

A transformation simply processes its input parameters leading to a number of
output parameters. As no cryptography is involved the security sets of output
parameters can simply be calculated from the union of all input security sets.

\TODO{Integrity and confidentiality are treated independently here. As
confidentiality requirements are known at the inputs of the system but cannot
be derived in a backward step (except by largely overapproximating it),
confidentiality is propagated from the sources of the model. Whenever an input
of a transformation has a confidentiality requirement, all outputs of that
transformation inherit it as any of the outputs may have been tainted by a
confidential input.

Contrary, integrity is derived bottom up starting from the sinks of the model.
The reason is, that integrity is only maintained if all sources of a
transformation have an integrity property, which cannot be derived in a forward
step.}

$$\trans(in_1^{\sigma_1}, \cdots, in_n^{\sigma_n}) \mapsto (out_1^{\cup\sigma_i},\cdots,out_m^{\cup\sigma_i})$$

A special case of a transformation is the $\const$ primitive which transfers a
constant input parameter to its output parameter.

$$\const(const^{\sigma}) \mapsto (const^{\sigma})$$

Another special case of a transformation is $\permute$, a primitive which
permutes a set of input arguments into another set of output arguments. While
the order input argument determines the output permutation, its security set
does not have an influence on the security of the other parameters.

\TODO{Formulas need to be change to predicates anyway. Add permute later.}

\TODO{Sounds like this element can be unsafe in many cases. Discuss that where it's safe to use.}

\subsubsection{Data flow dependencies}

In some cryptographic protocols messages may only be sent out after an
authentication step of a peer has been performed using some independent
incoming message. To model situations where two independent primitives have
data flow dependencies without actually exchanging any data, the guard
primitive can be used. It outputs its $data$ input parameter unmodified if the
input parameter $cond$ does not equal $\emptysec$. 

\begin{equation*}
\guard(data^{\sigma}, cond^{\{i\}}) \mapsto
    \begin{cases}
        \emptysec,      & \text{if $cond = \emptysec$} \\
        data^{\sigma},  & \text{otherwise}
    \end{cases}
\end{equation*}

\subsubsection{Random Numbers}

$$\rand(len^{\{i\}}) \mapsto data^{\{c,i,f\}}$$

\subsubsection{Hashing}

A cryptographic hash function efficiently computes a fixed-length hash value
$h$ for any message $m$ of arbitrary length. They are often called one-way hash
functions, as it is infeasible for an attacker to recreate the input message
from it hash value or to find two different messages resulting in the same hash
value. Furthermore, even smallest changes in an input message result in
significant changes in the resulting hash.

As a hash $h$ uniquely identifies an input message $m$, it can be used to prove
knowledge of $m$ without revealing it. A hash function thus eliminates a
potential confidentiality requirement in the input security set, but does not
influence integrity or freshness requirements:

$$\hash(msg^\sigma) \mapsto hash^{\sigma\secminus\{c\}}$$

\TODO{Is freshness really not influenced by a hash function?}

The inverse function\footnote{Obviously, an efficient inverse function to a
one-way hash should not exist. We rather refer to an inverse function as the
operation that is typically used by the receiver of a hash to validate that a
message yields a specific hash value.} takes a message $m$ and a hash
value $h$ as input and returns the boolean value of $hash(m) = h$.

$$\hashvrfy(hash^\emptysec, msg^\sigma) \mapsto msg^{\sigma} | \emptysec$$

\TODO{How does $\hashvrfy$ influence the security requirement sets?}

\subsubsection{Message authentication}

$$\hmac(key^{\{c,i\}}, msg^\sigma) \mapsto (auth^{\emptysec})$$

$$\hmacinline(key^{\{c,i\}}, msg^\sigma) \mapsto (msg^{\sigma\secminus{\{i\}}}, auth^{\emptysec})$$

$$\hmacvrfy(key^{\{c,i\}}, auth^\emptysec, msg^\sigma) \mapsto msg^{\sigma\cup\{i\}} | \emptysec$$

% While it looked interesting to never pass input data back in those functions,
% this does not seem to work consistently. If hmacvrfy() only returns a
% verdict on whether the MAC was valid for a message msg and we get pass on the
% message from the original source (i.e. the source hmacvrfy() got msg from,
% then we need to model a case where hmacvrfy() fails and msg does NOT flow
% from source to destination. This looks very ugly.
%
% Alternative idea: Never pass on explicit verdict, but the data or NIL.

\subsubsection{Digital Signatures}

$$\sign(pkey^{\{i\}}, skey^{\{c,i\}}, msg^\sigma) \mapsto auth^{\sigma\secminus\{i\}}$$

$$\signvrfy(pkey^{\{i\}}, auth^{\emptysec}, msg^\sigma) \mapsto msg^{\sigma\cup\{i\}} | \emptysec$$

\subsubsection{Diffie-Hellman Key Exchange}

$$\dhpub(gen^{\{i\}}, psec^{\{c,i,f\}}) \mapsto (pub^\sigma, psec^{\{c,i\}})$$

$$\dhsec(pub^\sigma, psec^{\{c,i\}}) \mapsto ssec^{\sigma\cup\{c\}} $$

\TODO{Is it true that we do not require freshness for psec in the dhsec operation? Intuitively it should be sufficient to require freshness in dhpub...}

\subsubsection{Symmetric Encryption}

\begin{equation*}
    \enc((iv^{\{i\}}, key^\gamma)^{\{f\}}, plaintext^\sigma) \mapsto
    \begin{cases}
        ciphertext^{\sigma\secminus\{c\}}, & \text{if $\{c,i\} \subseteq \gamma$} \\
        ciphertext^{\sigma},               & \text{otherwise}
    \end{cases}
\end{equation*}

\TODO{The freshness notation still looks a bit quirky}

\begin{equation*}
    \dec(iv^{\{i\}}, key^\gamma, ciphertext^\sigma) \mapsto
    \begin{cases}
        plaintext^{\sigma\cup\{c\}}, & \text{if $\{c,i\} \subseteq \gamma$} \\
        plaintext^{\sigma},          & \text{otherwise}
    \end{cases}
\end{equation*}

\subsubsection{Declassification}

This can be used to model situations where data with integrity or
confidentiality requirements is released. In the OTR protocol, this e.g.
happens when old MAC keys are published after they have been used to achieve
plausible deniability.

$$\release(data^\sigma) \mapsto data^\emptysec $$

\subsection{Security Requirements Graph}

Security requirements are not constant during a security protocol run. While
user input to a security messaging protocol must by kept confidential,
symmetric encryption operations remove this requirement such that the
information can be passed to a domain that does not guarantee confidentiality,
like the Internet. To identify different domains implied by a security protocol
and to know what guarantees each part of the needs to provide, a security
requirements graph for that protocol must be created systematically.

As we are interested in splitting up security protocols into components, we do
not associated a security level with the data flowing through the protocol
elements, as done in data flow analysis. Instead, data is tagged with a set of
security requirements (confidentiality, integrity, freshness) the environment
processing this data has to meet. Operations such as the primitives described
in the previous section take tagged data as their input and output tagged data
with potentially different sets of security requirements.

A security requirements graph consists of a set of nodes each of which
represents an operation as defined in \autoref{sec:notation}. Directed edges
between two nodes are labeled with a tuple $(src, dst, sec)$. The element $src$
denotes the output parameter of the sending node and $dst$ the respective input
parameter of the receiving node. The last element, $sec$, is the set of
security requirements the \emph{environment} storing or transferring the data
must guarantee.

\begin{figure}[ht]
    \centering
    \begin{dot2tex}[mathmode]
        digraph G
        {
            #rankdir=LR;
            node[shape=rect];
            rbits [label="128^{\{i\}}"];
            iv [label="0^{\{i\}}"];
            rand [label="Rand"];
            encrypt [label="Encrypt"];
            receive [label="Receive^{\{c\}}"];
            send [label="Send^\emptysec"];

            rbits -> rand [label="(const, len, ?)"];
            rand -> encrypt [label="(data, key, ?)"];
            receive -> encrypt [label="(msg, plaintext, ?)"];
            iv -> encrypt [label="(const, iv, ?)"];
            encrypt -> send [label="(ciphertext, msg, ?)"];
        }
    \end{dot2tex}
    \caption{Security requirements graph for a simplistic encryption scheme}
\end{figure}

\subsection{Algorithm}

In the initial graph, nodes may still have undetermined security requirements
set. This is true for operations like $\enc$ which take an unspecified set and
perform some transformation on it (like removing the confidentiality
requirement in the case of $\enc$). What is also missing initially, are the
security requirements sets for the edges which are later used to partition the
graph. The following algorithm calculates all undetermined requirements sets
and assigns requirements sets to all edges.

\end{document}
